# -*- coding: utf-8 -*-
"""Copy of Project - Web Application for Data Analytics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h7SfOBUKCIbjjP6MIXvkJlNu3jlvkmPc

# Project - Web Application for Data Analytics

## About the instructor:

**Ts. Nur Shakirah Md Salleh**

Lead Technical Trainer - Data, Analytic and Machine Learning

airasia academy

nurshakirahmdsalleh@airasiaacademy.com

LinkedIn: [Ts. Nur Shakirah Md Salleh](https://www.linkedin.com/in/nurshakirahmdsalleh)

Â©2023 [airasia academy](https://airasiaacademy.com) All rights reserved.

#Project

Instructions:
1. Develop a Python website to predict the number of sales and deploy it using Streamlit using GitHub repository.
2. You are require to use `Advertising.csv` dataset (Team Krypton) and `iris` dataset (Team Asgard) in this case study. Generate the model of this dataset outside of the streamlit environment (You can use Google Colab). You just need to load the model in this app (no model training should happens in this application).
3. You are require to choose only **ONE** of the most suitable supervised machine learning algorithm to solve this problem.
4. Feature scaling is optional for this project.
5. You need to enable slider to set the feature values.


**Submission**

Submit the following information:
* source code to generate the model (.pdf)
* screenshot of the source code (.py) on GitHub
* screenshot of the streamlit app

Import Libary
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

pd.options.display.max_columns = None
pd.options.display.max_rows = None

"""Load Iris dataset"""

df = sns.load_dataset("iris")

"""Slip into train and test dataset"""

from sklearn.model_selection import train_test_split
import tensorflow as tf

X=df.drop('species', axis=1)
y=df.species.copy()

#training and testing split using all feature
#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)

X

from sklearn import preprocessing
scaler = preprocessing.MinMaxScaler()
scaled = scaler.fit_transform(X)
df_scaled = pd.DataFrame(scaled)
df_scaled.columns = ['sepal_length','sepal_width', 'petal_length','petal_width']
df_scaled.head()

df_scaled.plot.hist()

#training and testing split using all feature
X_train, X_test, y_train, y_test = train_test_split(df_scaled, y, test_size=0.2, random_state=1, stratify=y)

print(X_train.shape)
print(y_train.shape)

print(X_test.shape)
print(y_test.shape)

X_train

"""Algorithm 3: Support Vector Machine"""

#C parameter. Large C: Low bias, high variance. Low C: High bias, low variance. C=1/lambda.
#kernel parameter. rbf, poly (polynomial), linear
from sklearn.svm import SVC

modelsvmc = SVC(kernel='linear', C=1).fit(X_train, y_train) #C=margin

#---optional---#
print('Accuracy of RBF SVC classifier on training set: {:.2f}'
     .format(modelsvmc.score(X_train, y_train)))
print('Accuracy of RBF SVC classifier on test set: {:.2f}'
     .format(modelsvmc.score(X_test, y_test)))
#---optional---#

from sklearn.metrics import accuracy_score
y_pred = modelsvmc.predict(X_test)
accuracy_score(y_test, y_pred)

from sklearn.metrics import confusion_matrix
cnf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cnf_matrix)

from sklearn.metrics import classification_report

# Assuming y_pred and y_test are already defined
# y_pred = svm_classifier.predict(X_test)

# Generate and print the classification report
print(classification_report(y_test, y_pred))

import pickle
pickle.dump(modelsvmc,open("Iris.h5","wb"))
print("model saved")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile iris-generate-predict.py
# import streamlit as st
# import pandas as pd
# import seaborn as sns
# from sklearn.naive_bayes import GaussianNB
# 
# st.write("# Simple Iris Flower Prediction App")
# st.write("This app predicts the **Iris flower** type!")
# 
# st.sidebar.header('User Input Parameters')
# 
# def user_input_features():
#     sepal_length = st.sidebar.slider('Sepal length', 4.3, 7.9, 5.4)
#     sepal_width = st.sidebar.slider('Sepal width', 2.0, 4.4, 3.4)
#     petal_length = st.sidebar.slider('Petal length', 1.0, 6.9, 1.3)
#     petal_width = st.sidebar.slider('Petal width', 0.1, 2.5, 0.2)
#     data = {'sepal_length': sepal_length,
#             'sepal_width': sepal_width,
#             'petal_length': petal_length,
#             'petal_width': petal_width}
#     features = pd.DataFrame(data, index=[0])
#     return features
# 
# df = user_input_features()
# 
# st.subheader('User Input parameters')
# st.write(df)
# 
# 
# prediction = modelGaussianIris.predict(df)
# prediction_proba = modelGaussianIris.predict_proba(df)
# 
# st.subheader('Class labels and their corresponding index number')
# st.write(Y.unique())
# 
# st.subheader('Prediction')
# st.write(prediction)
# 
# st.subheader('Prediction Probability')
# st.write(prediction_proba)